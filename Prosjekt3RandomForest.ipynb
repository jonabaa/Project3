{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - What's cooking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "All the imports go here, to make it easier to find them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, log_loss\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reding in the training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('train.json') \n",
    "\n",
    "print(\"An example of what the data looks like:\")\n",
    "print(\"\")\n",
    "print(data)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Here the number of recepies of each cuisine\")\n",
    "print(\"\")\n",
    "print(data['cuisine'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The set of different cuisines\n",
    "cuisines = data.cuisine.unique()\n",
    "\n",
    "# To find the different ingredients, we need to clean them up a little. \n",
    "def clean(string) :\n",
    "    s = string.replace('-',' ') # read low-fat the same as low fat\n",
    "    s = string.replace('&', 'and') # read & and and as the same \n",
    "    s = re.sub('\\((.*?)\\)', '', s) # remove everythin g in brackets\n",
    "    s = re.sub('\\d{1,2}\\%', '', s) # remove things of the form d% or dd%, where d is a digit\n",
    "    s = ' '.join(s.split()) # remove extra white spaces\n",
    "    \n",
    "    return s\n",
    "\n",
    "ing_list = data.ingredients.values.tolist()\n",
    "raw_ingredients = [clean(x) for ing in ing_list for x in ing]\n",
    "\n",
    "ingredients = sorted(set(raw_ingredients))\n",
    "\n",
    "print(\"There are %d different ingredients.\" % len(ingredients))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Here is the very long list:\")\n",
    "print(\"\")\n",
    "print(ingredients)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipies as vectors\n",
    "\n",
    "Here we have functions that take a list of incredients and produces a vector to represent them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a dictionary that to each ingredient assigns its index\n",
    "ingredient_index = {}\n",
    "for i in range(0,len(ingredients)) :\n",
    "    ingredient_index[ingredients[i]] = i\n",
    "\n",
    "# the same for cuisines \n",
    "cuisine_index = {}\n",
    "for i in range(0, len(cuisines)) : \n",
    "    cuisine_index[cuisines[i]] = i \n",
    "    \n",
    "def ingredients_to_vector(ings) :\n",
    "    vect = np.zeros(len(ingredients))\n",
    "    for ing in ings :\n",
    "        vect[ingredient_index[clean(ing)]] = 1\n",
    "        \n",
    "    return vect\n",
    "\n",
    "def cuisine_to_vector(cus) : \n",
    "    vect = np.zeros(20)\n",
    "    vect[cuisine_index[cus]] = 1\n",
    "    return vect\n",
    "\n",
    "vect_list = [ingredients_to_vector(ing) for ing in ing_list]\n",
    "target_list = [cuisine_to_vector(cus) for cus in data.cuisine.values.tolist()]\n",
    "\n",
    "print(len(vect_list))\n",
    "print(len(target_list))\n",
    "\n",
    "print(vect_list[30064])\n",
    "print(target_list[30064])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in random.sample(target_list, 20) :\n",
    "    print(t)\n",
    "    \n",
    "print(cuisine_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.c_[vect_list]\n",
    "Y = np.c_[target_list]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
    "\n",
    "print('Shape of x_train: '+ str(x_train.shape))\n",
    "print('Shape of y_train: '+ str(y_train.shape))\n",
    "print()\n",
    "print('Shape of x_test: '+ str(x_test.shape))\n",
    "print('Shape of y_test: '+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alter the target data to output numbers instead of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_num = np.zeros((Y.shape[0]))\n",
    "for i in range(Y.shape[0]):\n",
    "    Y_num[i] = np.argmax(Y[i])\n",
    "\n",
    "print(Y_num)\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_num, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "Let's make some forests with different sizes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Starting training:')\n",
    "\n",
    "for i in [1, 10, 20, 50, 100]:\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=None, max_features=None,\n",
    "                             verbose=True, n_jobs=8)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print()\n",
    "    print('Some guesses: ' + str(clf.predict(x_test[90:95])))\n",
    "    print('Actual answers: ' + str(y_test[90:95]))\n",
    "    \n",
    "    print('Accuracy on test data when we have %s tree(s):' %i)\n",
    "    print(clf.score(x_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with more trees forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 100 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6756756756756757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 31.0min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 150 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752985543683218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed: 41.5min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 200 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6732872407291012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed: 52.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 250 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6736643620364551\n"
     ]
    }
   ],
   "source": [
    "print('Starting training:')\n",
    "\n",
    "for i in [100, 150, 200, 250]:\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=None, max_features=None,\n",
    "                             verbose=True, n_jobs=8)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print()\n",
    "    print('Some guesses: ' + str(clf.predict(x_test[90:95])))\n",
    "    print('Actual answers: ' + str(y_test[90:95]))\n",
    "    \n",
    "    print('Accuracy on test data when we have %s tree(s):' %i)\n",
    "    print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with the square root as n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 100 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7088623507228159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:   56.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 150 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71024512884978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [ 6. 10.  1.  1.  3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 200 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145191703331238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some guesses: [6. 3. 1. 1. 3.]\n",
      "Actual answers: [ 6.  3. 12. 14.  3.]\n",
      "Accuracy on test data when we have 250 tree(s):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133878064110623\n"
     ]
    }
   ],
   "source": [
    "print('Starting training:')\n",
    "\n",
    "for i in [100, 150, 200, 250]:\n",
    "    clf = RandomForestClassifier(n_estimators=i, max_depth=None,\n",
    "                             verbose=True, n_jobs=8)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print()\n",
    "    print('Some guesses: ' + str(clf.predict(x_test[90:95])))\n",
    "    print('Actual answers: ' + str(y_test[90:95]))\n",
    "    \n",
    "    print('Accuracy on test data when we have %s tree(s):' %i)\n",
    "    print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
