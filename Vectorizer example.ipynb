{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import random\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, log_loss\n",
    "from sklearn import svm #support vector machines\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('train.json') \n",
    "\n",
    "print(\"An example of what the data looks like:\")\n",
    "print(\"\")\n",
    "print(data)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Here the number of recepies of each cuisine\")\n",
    "print(\"\")\n",
    "print(data['cuisine'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipie_list_list = data.ingredients.values.tolist()\n",
    "recipie_string_list = [\" \".join(ing) for ing in recipie_list_list]\n",
    "vectorizer = CountVectorizer(min_df = 0.001)\n",
    "X = vectorizer.fit_transform(recipie_string_list).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_recipie_list_list = (data.head()).ingredients.values.tolist()\n",
    "head_recipie_string_list = [\" \".join(ing) for ing in head_recipie_list_list]\n",
    "vectorizer = CountVectorizer( ngram_range = (1, 1) )\n",
    "head_X = vectorizer.fit_transform(head_recipie_string_list).toarray()\n",
    "\n",
    "for recipie in head_recipie_string_list :\n",
    "    print(recipie)\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"The matrix looks like this:\")\n",
    "print(head_X)\n",
    "\n",
    "print(\"\")\n",
    "print(\"The feature names are:\")\n",
    "print(vectorizer.get_feature_names())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat map code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## This is code to do neat plotting, taken from:\n",
    "# https://matplotlib.org/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n",
    "############################################################################\n",
    "############################################################################\n",
    "############################################################################\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Arguments:\n",
    "        im         : The AxesImage to be labeled.\n",
    "    Optional arguments:\n",
    "        data       : Data used to annotate. If None, the image's data is used.\n",
    "        valfmt     : The format of the annotations inside the heatmap.\n",
    "                     This should either use the string format method, e.g.\n",
    "                     \"$ {x:.2f}\", or be a :class:`matplotlib.ticker.Formatter`.\n",
    "        textcolors : A list or array of two color specifications. The first is\n",
    "                     used for values below a threshold, the second for those\n",
    "                     above.\n",
    "        threshold  : Value in data units according to which the colors from\n",
    "                     textcolors are applied. If None (the default) uses the\n",
    "                     middle of the colormap as separation.\n",
    "\n",
    "    Further arguments are passed on to the created text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[im.norm(data[i, j]) > threshold])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "############################################################################\n",
    "############################################################################\n",
    "############################################################################\n",
    "##### plotting code over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the mses in a heat map\n",
    "fig, ax = plt.subplots()\n",
    "im, cbar = heatmap(np.array([56,67]).reshape(1,2), np.array([1]), np.array([0.001, 00.1]) , ax=ax, cmap=\"YlGn\", cbarlabel=\"MSE\")\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.4f}\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_design_matrix(cleaning_function = lambda x : x, min_df = 0.0, max_df = 1.0) :\n",
    "    \"\"\"\n",
    "    Take a data frame data, and convert to a matrix. \n",
    "    Use cleaning_function to clear up data. \n",
    "    \"\"\"\n",
    "    data = pd.read_json('train.json') \n",
    "    recipie_list_list = data.ingredients.values.tolist()\n",
    "    recipie_string_list = [cleaning_function(\" \".join(ing)) for ing in recipie_list_list]\n",
    "    vectorizer = CountVectorizer(min_df = min_df, max_df = max_df)\n",
    "    X = vectorizer.fit_transform(recipie_string_list)\n",
    "    y = data.cuisine.values\n",
    "    return X, y, vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "def clean(s) :\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    return s.replace(\"33\", \"\")\n",
    "\n",
    "\n",
    "def clf_cross_validator(X_train, y_train, clf_constructor, p_list, q_list = [], folds = 10, plot = False, label = '') :\n",
    "    \"\"\"\n",
    "    A general method to preform cross validation of sci_kit learn method. \n",
    "    Takes:\n",
    "    Training data (X_train, y_train)\n",
    "    A function clf_constructor which builds a sci_kit learn classifier\n",
    "    p_list a list of parameters to varry\n",
    "    q_list a possible second list to varry, \n",
    "    folds the number of folds to use for cross validation\n",
    "    plot determines if a heatmap of the results should be printed\n",
    "    label is the label of the plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    # we rename the constructor, \n",
    "    # only playes a role if q_list is empty \n",
    "    constructor = clf_constructor  \n",
    "    \n",
    "    ####\n",
    "    # If we are only passed one list, \n",
    "    # modify the constructor to take a second dummy argument\n",
    "    # We make q_list be a singleton list, \n",
    "    # and flip the role of p_list and q_list, the latter being only for printing purposes \n",
    "    if not q_list : # true if q_list is empty \n",
    "        q_list = p_list\n",
    "        p_list = ['']\n",
    "        constructor = (lambda p,q : clf_constructor(q)) \n",
    "    \n",
    "    ###\n",
    "    # We loop over the parameters \n",
    "    # and record the avarage of each folds score    \n",
    "    for p in p_list :\n",
    "        for q in q_list :\n",
    "            clf = constructor(p,q)\n",
    "            score = cross_val_score(clf, X_train, y_train, cv=folds)\n",
    "            scores.append(np.mean(score))\n",
    "\n",
    "    # transform the scores to a len(p_list) x len(q_list) shape array\n",
    "    scores_array = np.array(scores).reshape(len(p_list), len(q_list))\n",
    "            \n",
    "    ####\n",
    "    # make a heat map of the scores\n",
    "    if plot :\n",
    "        fig, ax = plt.subplots()\n",
    "        im, cbar = heatmap(scores_array, np.array(p_list), np.array(q_list) , ax = ax, cmap = \"YlGn\", cbarlabel = label )\n",
    "        texts = annotate_heatmap(im, valfmt=\"{x:.4f}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return scores_array\n",
    "\n",
    "    \n",
    "def svm_tester(X_train, y_train, C_list = [0.1], folds = 10, plot = False) :\n",
    "    \"\"\"\n",
    "    Test the svm parameter C using cross validation\n",
    "    For each C in C_list do folds fold cross validation, \n",
    "    returns an array, of the same size as C_list, \n",
    "    of the avarages of the accuracies for each fold.\n",
    "    \n",
    "    If plot is set to true, show a heatmap of the results\n",
    "    \"\"\"\n",
    "\n",
    "    svm_constructor = (lambda p : svm.LinearSVC(C = p)) \n",
    "    scores = clf_cross_validator(X_train, y_train, svm_constructor, C_list, folds = folds, plot = plot, label = 'accuracy')\n",
    "    return scores \n",
    "\n",
    "def forrest_tester(X_train, y_train, trees_list = [1], depth_list = [1], folds = 10, plot = False) :\n",
    "    \"\"\"\n",
    "    Test the random forrest for the parameters of number of trees and max depth using cross validation\n",
    "    For each pair of parameters do folds fold cross validation, \n",
    "    returns an array, of shape len(trees_list) x len(depth_list) \n",
    "    of the avarages of the accuracies for each fold.\n",
    "    \n",
    "    If plot is set to true, show a heatmap of the results\n",
    "    \"\"\"\n",
    "    \n",
    "    forrest_constructor = (lambda p,q : RandomForestClassifier(n_estimators = p, max_depth = q)) \n",
    "    scores = clf_cross_validator(X_train, y_train, forrest_constructor, trees_list, depth_list, folds = folds, plot = plot, label = 'accuracy')\n",
    "    return scores \n",
    "\n",
    "def logistic_tester(X_train, y_train, C_list = [0.1], folds = 10, plot = False) :\n",
    "    \"\"\"\n",
    "    Test the logistic regression parameter C using cross validation\n",
    "    For each C in C_list do folds fold cross validation, \n",
    "    returns an array, of the same size as C_list, \n",
    "    of the avarages of the accuracies for each fold.\n",
    "    \n",
    "    If plot is set to true, show a heatmap of the results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Not really sure about the solver\n",
    "    logistic_constructor = (lambda p : LogisticRegression(solver='lbfgs', multi_class='multinomial', C = p)) \n",
    "    scores = clf_cross_validator(X_train, y_train, logistic_constructor, C_list, folds = folds, plot = plot, label = 'accuracy')\n",
    "    return scores \n",
    "\n",
    "def mlp_tester(X_train, y_train, nodes = [1], alpha_list = [0.001], folds = 10, plot = False) :\n",
    "    \"\"\"\n",
    "    Test the mlp classifier (neural net) for the parameters of \n",
    "    number of nodes in a single layer and regularization constant using cross validation.\n",
    "    For each pair of parameters do folds fold cross validation, \n",
    "    returns an array, of shape len(nodes) x len(alpha_list) \n",
    "    of the avarages of the accuracies for each fold.\n",
    "    \n",
    "    If plot is set to true, show a heatmap of the results\n",
    "    \"\"\"\n",
    "    \n",
    "    mlp_constructor = (lambda p,q : MLPClassifier(hidden_layer_sizes = (p), alpha = q)) \n",
    "    scores = clf_cross_validator(X_train, y_train, mlp_constructor, nodes, alpha_list, folds = folds, plot = plot, label = 'accuracy')\n",
    "    return scores\n",
    "\n",
    "\n",
    "### Also want voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features = get_design_matrix(min_df = 0.00013)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_scores = forrest_tester(x_train, y_train, [10,20,30], [5,10], folds = 2, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores = svm_tester(x_train, y_train, [0.001, 0.01, 0.1, 1], folds = 2, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_scores = logistic_tester(x_train, y_train, [0.001, 0.01, 0.1, 1, 10], folds = 2, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_scores = mlp_tester(x_train, y_train, [10,20,30], [0.0001, 0.001], folds = 2, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tryingout polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('train.json') \n",
    "recipie_list_list = data.ingredients.values.tolist()\n",
    "recipie_string_list = [\" \".join(ing) for ing in recipie_list_list]\n",
    "vectorizer = CountVectorizer(min_df = 0.01)\n",
    "X = vectorizer.fit_transform(recipie_string_list).toarray()\n",
    "y = data.cuisine.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data,  \n",
    "del recipie_list_list, recipie_string_list\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-df7545457070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteraction_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m         \u001b[1;31m# allocate output data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mXP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_output_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m         combinations = self._combinations(n_features, self.degree,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only = True, include_bias = False)\n",
    "px_train = poly.fit_transform(x_train)\n",
    "del x_train\n",
    "px_test = poly.fit_transform(x_test)\n",
    "del x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using min_df of 0.01, 2 degree features and an SVM classifier\n",
      "We got an accuracy of 0.722942.4\n"
     ]
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C = 0.1)\n",
    "clf.fit(px_train, y_train)\n",
    "predictions = clf.predict(px_test)\n",
    "print(\"We are using min_df of 0.01, 2 degree features and an SVM classifier\")\n",
    "print(\"We got an accuracy of %.4f\" % accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
